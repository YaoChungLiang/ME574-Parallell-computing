{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Numerical Integration (a.k.a Quadrature)\n",
    "\n",
    "We have looked at numerical estimation of derivatives based on truncate Taylor series and applied it to constructing numerical solution techniques for both ordinary differential equations (ODEs) and partial differential equations (PDEs). Now we move on to dealing with other fundamental operation of calculus: __numerical integration__ (a.k.a. __numerical quadrature__).\n",
    "\n",
    "Let's start with the simplest case of a finite 1D domain, i.e. the interval $x \\in [a,b]$, and apply the basic ideas arising from the simplest definition of the integral:\n",
    "$$\\int_{a}^{b} f(x) dx = \\lim_{h\\to 0} \\sum\\limits_{j=0}^{N} f(x_j) h$$\n",
    "\n",
    "where $b-a = N h$. When you were first introduced to this idea, you may have estimated the value of the integral by plotting the function on graph paper and counting the boxes (quadrangles) under the graph. This get pretty close to the origin of the term quadrature which the Pythagoreans understood as finding a square with area equivalent to that of another figure; knowing how to compute area of a square, quadrture then provided the means for finding areas of other shapes.\n",
    "\n",
    "Based on the significance of the term __quadrature__ in the history of integration,  it is very common to use $Q[f]$ as the name for the estimated value of the integral of $f$ over a specified interval. For our purposes, we can think of $Q[f]$ as referring to a version of an integration scheme obtained from the actual \"calculus definition\" by discretizing the domain (evaluating $f$ at a discrete set of points $\\{x_i\\}$), removing the limit and replacing the differential $dx$ with a small but finite spacing $h$ (again because digital computation based on floating-point arithmetic does not include infinitesimal numbers). In the simplest case above, the evaluation points are all equally spaced ($x_i = x_0 + i h$) and all the values are equally weighted, but a more general scheme would have the form:\n",
    "\n",
    "$$Q[f] = \\sum\\limits_{i=0}^{N} w_i f(x_i) =  w_0 f(x_0) + w_1 f(x_1) + \\ldots + w_N f(x_N)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$Q[f] = \\sum\\limits_{i=0}^{N} w_i f_i =  w_0 f_0 + w_1 f_1 + \\ldots + w_N f_N$$\n",
    "\n",
    "where $f_i = f(x_i)$ and the actual value of the integral is\n",
    "$$\\int_{a}^{b} f(x) dx = Q[f] + E[f]$$\n",
    "\n",
    "where $E[f]$ is the error in approximating the integral by the quadrature sum.\n",
    "\n",
    "Now comes the practical question: How do you choose the evaluation points and weights in a systematic way so that you know something about how the error should behave?\n",
    "\n",
    "There are several families of popular methods.\n",
    "\n",
    "A simple and commonly used approach (that you have likely already seen in some form) called __Newton-Cotes__ formulas are based on polynomial interpolation. Consider the contribution to the integral from the sub-domain associated with a sequence of $n+1$ adjacent points (starting with $n=1$): \n",
    "\n",
    "$$\\{x_0, x_1\\}=\\{x_0, x_0 + h\\} \\text{ with function values } \\{f_0, f_1\\}$$\n",
    "\n",
    "Now approximate the function locally as a polynomial of degree $n = 1$, e.g. a line, and use our major tool (Taylor series) to produce an estimate of truncation error:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\int_{x_0}^{x_0 + h} f(x) dx &= Q[f] + E[f] \\\\\n",
    "&= \\int_{x_0}^{x_0 + h} \\big(f_0 + \\frac{f_1-f_0}{h} (x-x_0) \\big) dx + \\int_{x_0}^{x_0 + h} O(x-x_0)^2 dx \\\\\n",
    "\\end{aligned}\n",
    "$$ \n",
    "\n",
    "Now integrate the polynomial terms:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\int_{x_0}^{x_0 + h} f(x) dx = Q[f] + E[f] &= \\big(f_0 (x-x_0) + \\frac{f_1 - f_0}{2 h}(x-x_0)^2 \\big) \\Bigr\\rvert_{x-x_0 = 0}^h + O((x-x_0)^3)\\Bigr\\rvert_{x-x_0 = 0}^h \\\\\n",
    "\\int_{x_0}^{x_0 + h} f(x) dx = Q[f] + E[f] &= \\big(f_0 h + \\frac{f_1 - f_0}{2h}h^2 \\big) + O(h^3) \\\\\n",
    "\\int_{x_0}^{x_0 + h} f(x) dx = Q[f] + E[f] &= \\big( h\\; \\frac{f_0 + f_1}{2} \\big) + O(h^3)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "So the contribution from the interval between adjacent evaluation points is the spacing times the average of the function values which coincides with the area of the trapezoid between the interpolating line and the $x$-axis $\\implies$ __trapezoidal rule__\n",
    "\n",
    "\n",
    "The local error is $O(h^3)$ with a coefficient whose bounds depends on the local maximum of $f''(x)$, so it is reasonable to expect this method to work well on a small interval over which $f'(x)$ does not change much; i.e. the function is locally well-approximated by a linear interpolant.\n",
    "\n",
    "What do you do if you need to deal with a larger interval (over which the slope changes significantly)?\n",
    "\n",
    "__Composite method__ $\\iff$ break the big interval up into small intervals (where the linear approximant makes sense) and sum the contributions from the small intervals:\n",
    "\n",
    "![](trap_rule.png)\n",
    "\n",
    "$$\\text{\\bf{Composite Trapezoidal Rule}}$$\n",
    "\n",
    "$$\\int_{a}^{b} f(x) dx = \\int_{x_0}^{x_N} f(x) dx \\sim Q[f] = \\sum_{j=0}^{N-1} \\frac{h}{2} (f_j + f_{j+1})$$\n",
    "\n",
    "$$Q[f] = \\frac{h}{2} (f_0 + f_1) + \\frac{h}{2} (f_0 + f_1) + \\frac{h}{2} (f_1 + f_2) + \\ldots +  \\frac{h}{2} (f_{N-1} + f_N)$$\n",
    "\n",
    "$$Q[f] = \\frac{h}{2} (f_0 + 2 f_1 + 2 f_2 + \\ldots + 2 f_{N-1} + f_N)$$\n",
    "\n",
    "This is the classic formula for uniform spacing.\n",
    "\n",
    "\n",
    "\n",
    "Let's look at how it works and how the error depends on the spacing. A first implementation might look like the following (which returns a tuple containing the spacing and the quadrature value:\n",
    "\n",
    "```\n",
    "def trap_rule(fun,a,b,n):\n",
    "    \"\"\"\n",
    "    perform trapezoidal rule quadrature\n",
    "    \n",
    "    Args:\n",
    "        fun: name of integrand function\n",
    "        a, b: numerical integration limits (a<b)\n",
    "        n: integer number of quadrature subintervals\n",
    "    Returns:\n",
    "        h: spacing between quadrature points\n",
    "        quad: trapezoidal rule quadrature value    \n",
    "    \"\"\"\n",
    "    x = np.linspace(a,b,n+1)\n",
    "    h = (b-a)/n\n",
    "    f = np.zeros(n+1)\n",
    "    for i in range (n+1):\n",
    "        f[i] = fun(x[i])\n",
    "    quad = 0.5*h*(2*np.sum(f) - f[0] - f[-1])\n",
    "    return h, quad\n",
    "```\n",
    "\n",
    "Test the `trap_rule` function to compute $\\int_a^b sin(x) dx$ for which the exact value is $2$. This method succeeds in producing numerical approximations of the value of the integral, but it gets slow with large number of evaluation points. Let's look at how the error depends on the spacing (and/or evaluation point count), but let's also include timing results using `timeit.default_timer`:\n",
    "\n",
    "```\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "n = 8 #maximum exponent of h\n",
    "a = 0.\n",
    "b = np.pi\n",
    "e_trap = np.zeros(n) #initialize array to store error values\n",
    "h_vals = np.zeros(n) #initialize array to store spacing values\n",
    "n_vals = np.zeros(n) #initialize array to store number of points\n",
    "times = np.zeros(n) #initialize array to store computation times\n",
    "print(\"  h      Absolute Error    Time\")\n",
    "for i in range(n):\n",
    "    m = 10**(i+1)\n",
    "    start = timer()\n",
    "    h, est =  trap_rule(np.sin,a,b,m)\n",
    "    end = timer()\n",
    "    times[i] = (end - start) # Time in seconds\n",
    "    error = np.abs(exact-est)\n",
    "    e_trap[i] = error\n",
    "    h_vals[i] = h\n",
    "    n_vals[i] = m+1\n",
    "    print('{:1.0e} {: 1.14f} {: 1.3e}'.format(h,e_trap[i], times[i]))\n",
    "```\n",
    "\n",
    "\n",
    "|h      |Absolute Error    |Time\n",
    "|---      |---    |---\n",
    "|3e-01  |0.01647646249055  |5.360e-05\n",
    "|3e-02  |0.00016449611256  |2.259e-04\n",
    "|3e-03  |0.00000164493431  |8.920e-04\n",
    "|3e-04  |0.00000001644963  |1.377e-02\n",
    "|3e-05  |0.00000000016488  |9.622e-02\n",
    "|3e-06  |0.00000000000649  |9.584e-01\n",
    "|3e-07  |0.00000000041355  |1.062e+01\n",
    "|3e-08  |0.00000000355681  |9.903e+01\n",
    "\n",
    "As the sacing is dcreased, the error initially shrinks according to a power law: a log-log plot with slope $\\approx -2$ indicates truncation error $\\sim O(h^{2})$. Remember that making the spacing too small not only involves a long computation time, it can also cause the error to increase (as roundoff becomes the dominant error source).\n",
    "\n",
    "How does this match up with the fact that the error term above is $\\sim O(h^{3})$? That is the __local__ error.\n",
    "\n",
    "The number of intervals $\\sim O(h^{-1})$, so the global error for the trapezoidal rule is $\\sim O(h^{3} h^{-1}) = O(h^{2})$.\n",
    "\n",
    "![](quadrature_data.png)\n",
    "\n",
    "For `h < 1e-5`, in addition to growing errors, we also observe runtimes that are becoming impractical. (For `1e8` points, the trapezoidal rule evaluation took almost 2 minutes.)\n",
    "\n",
    "### What can we do to get more accurate results without spending excessive amounts of time?\n",
    "\n",
    "There are a couple very standard approaches (higher order quadrature rules and adaptive subdivision), but before we go there let's see if we can squeeze more accuracy out of what we have already done with the trapezoidal rule based on what we know about the truncation error; i.e. the global error is $O(h^{2})$.\n",
    "\n",
    "Let's call the exact value $F$ and $Q(h)$ the quadrature value with spacing $h$. Then we have: \n",
    "$$F = Q(h) + c_2 h^2 + c_3 h^3 + \\ldots$$ \n",
    "\n",
    "Similarly we can consider using only every other quadrature point so the spacing is $2h$, for which:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "F &= Q(2h) + c_2 (2h)^2 + c_3 (2h)^3 + \\ldots \\\\\n",
    "&= Q(2h) + 4 c_2 h^2 + 8 c_3 h^3 + \\ldots\n",
    "\\end{aligned}$$\n",
    "\n",
    "Multiplying the first equation by $2^2$ and subtracting, we can cancel out the leading term in the truncation error to obtain:\n",
    "\n",
    "$$3 F = 4 Q(h) -Q(2h) + O(h^3)$$ or $$F =\\frac{ 4 Q(h) -Q(2h)}{3} + O(h^3)$$\n",
    "\n",
    "This approach is known as __Richardson extrapolation__, and it is worth keeping in mind because it can provide significant error reduction without much extra work\n",
    "\n",
    "## Return to considering other approaches for error reduction:\n",
    "\n",
    "### Higher order quadrature methods\n",
    "\n",
    "We obtained the trapezoidal rule by considering a \"panel\" consisting of the interval between $n+1=2$ quadrature points and approximating the integrand locally with a polynomial of degree $n=1$.\n",
    "\n",
    "The __Newton-Cotes__ family of quadrature methods generalizes this approach by approximating a panel of $n+1$ points with a degree $n$ polynomial.\n",
    "\n",
    "The next member of the family, approximating 3 points with a degree 2 polynomial (i.e. a quadratic), is known as ___Simpson's rule___:\n",
    "\n",
    "$$\\int_{x_j}^{x_{j+2}} f(x) dx = \\frac{h}{3} (f_j + 4 f_{j+1} + f_{j+2}) - \\frac{h^5}{90}f''''(c)$$\n",
    "\n",
    "![](simpsons_rule.png)\n",
    "\n",
    "$$\\text{\\bf{Simpson's rule using parabolic interpolation of 3 points}}$$\n",
    "\n",
    "The multi-panel version is known as __composite Simpson's rule__:\n",
    "$$Q_S = \\frac{h}{3} ( f_0 + 4 f_1 + 2 f_2 +4 f_3 +2 f_5 +\\ldots+2f_{N-2} +4 f_N-1 + f_N)$$\n",
    "\n",
    "Here is a serial implementation of Simpson's rule:\n",
    "\n",
    "```\n",
    "#implement Simpson's rule\n",
    "def simpson(f,a,b,n):\n",
    "    \"\"\"\n",
    "    perform trapezoidal rule quadrature\n",
    "    \n",
    "    Args:\n",
    "        fun: name of integrand function\n",
    "        a, b: numerical integration limits (a<b)\n",
    "        n: integer number of quadrature panels\n",
    "    Returns:\n",
    "        h: spacing between quadrature points\n",
    "        quad: trapezoidal rule quadrature value    \n",
    "    \"\"\"\n",
    "    h = (b-a)/(2*n)\n",
    "    x = a + h\n",
    "    quad = f(a) + 4*f(x) + f(b)\n",
    "    sum = 3\n",
    "    for i in range (1,n):\n",
    "        x += h\n",
    "        quad += 2*f(x)\n",
    "        x += h\n",
    "        quad += 4*f(x)\n",
    "        sum += 2\n",
    "    return h, (h/3)*quad\n",
    "```\n",
    "\n",
    "Applying the sample Simpson's rule implementation above, error estimates were computed for the same sample integral considered above, $\\int_a^b sin(x) dx.$ Those results are shown below in yellow along with the error results for the trapezoidal rule shown in blue.\n",
    "\n",
    "![](simpson_vs_trap.png)\n",
    "\n",
    "Note that Simpson's rule data has initial slope $\\approx -4$ consistent with $4^{th}$-order accuracy. The improved truncation error causes the roundoff error to become dominant at larger spacing (compared to the trapezoidal rule). However, by utilizing an appropriate spacing Simpson's tule provides better accuracy with fewer sample points and shorter computation time.\n",
    "\n",
    "There are many other families of quadrature schemes (e.g. Gauss-Kronrod, Clenshaw-Curtis) that employ non-uniform spacings, and you are encouraged to explore further if such things are of interest. \n",
    "\n",
    "However, our focus is on parallelization, so let's consider parallel implementation of composite Newton-Cotes schemes such as Simpson's rule.\n",
    "\n",
    "Based on your experience with parallel codes, consider the steps in computing a Simppson's rule quadrature and describe them in terms of parallel computing patterns:\n",
    "\n",
    "- Evaluate the function on a grid of points $\\equiv$ ???\n",
    "- Compute a fixed linear combination of neighboring values corresponding to a panel $\\equiv$ ???\n",
    "- Sum the panel contributions $\\equiv$ ???\n",
    "\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "$$map + stencil + reduce = quadrature$$\n",
    "\n",
    "Note that the stencil is computed with $span=n$. For Simpson with $n=3$ points contributing to a panel, the panels are associated with indices $i = \\{\\{0,1,2\\},\\{3,4,5\\},\\{6,7,8\\},\\ldots\\}$. The stencil of radius 1 ($\\frac{h}{3} [1,4,1]$) is then applied with span $2n+1=3$ at $i=1,4,7,\\ldots$\n",
    "\n",
    "> This provides perfect opportunity to flex your parallel computing muscles, so expect a parallel composit Simpson's problem on HW#4.\n",
    "\n",
    "A typical and practical embellishment that applies to most quadratures schemes is to employ adaptive subdivision to achieve greater accuracy while maintaining reasonable computational efficiency.\n",
    "\n",
    "## Adaptive subdivision\n",
    "\n",
    "Our quick detour into Richardson extrapolation indicated that we can get an estimate of quadrature error by __downsampling__; i.e. by ignoring every other quadrature point. Thus we obtain $Q(h)$ and $Q(2h)$, and we can use the difference in their values to estimate the error. Adaptive subdivision employs this technique on a panel by panel basis as follows:\n",
    "\n",
    "To evaluate the integral over an interval to within a specified tolerance:\n",
    "\n",
    "1) Apply an initial quadrature scheme to obtain an initial estimate $Q_{old}$.\n",
    "Subdivide each panel and apply the quadrature scheme on the subpanels to obtain $Q_{left}$ and $Q_{right}$.\n",
    "\n",
    "2) Use $Q_{left} + Q_{right} - Q_{old}$ as a measure of local error for the panel.\n",
    "\n",
    "3) Continue subdiving panels with largest error until sum of changes due to panel subdivision are less that global error tolerance.\n",
    "\n",
    "It may be practical to divide up the global error into a local error tolerance that can be applied independently while subdividing the panels.\n",
    "\n",
    "### Notes on parallelization:\n",
    "_ The \"natural\" parallelization approach is to launch a computational grid to evaluate kernels to perform the map, stencil, and reduction steps.\n",
    "- Executing that approach recursively (i.e., enabling a thread that detects large error to perform local refinement by launching another more \"focused\" grid) involves ___dynamic parallelism___. We will not spend time pursuing that, because dynamic parallelism is one of the aspects of CUDA that is not yet supported in numba.\n",
    "\n",
    "At this point, we have reasonable methods for computing values of integrals for functions of a single variable (on 1D domain), but that leaves a BIG question:\n",
    "\n",
    "## Question to ponder:\n",
    "### How do we compute integrals of functions of multiple variables on multi-dimensional domains? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
