{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ME 574 Spring 2020 Homework #5 - Due Thursday June 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This homework involves exploring CUDA-powered libraries/modules/packages.\n",
    "\n",
    "__1)__  We looked at the sample code file `fft_demo.py` that demonstrates how to use some of the functionality provided by the the fast fourier transform module `numpy.fft` to accomplish common tasks like filtering and differentiation. Here we want to take the next step and employ the parallel fast fourier transform module provided by `cupy` which is billed as \"A NumPy-compatible matrix library accelerated by CUDA\". For more info about `cupy` you can check out the website:\n",
    "\n",
    "https://cupy.chainer.org/\n",
    "\n",
    "This problem focuses on using the `cupy.fft` module which aims to provide a \"drop-in\" parallel replacement for `numpy.fft` which means that they aim to provide GPU-accelerated versions of the same functionality with matching function calls (i.e., the same function names and arguments).\n",
    "\n",
    "__1a)__ Install `cupy`. Their website gives full installation instructions, but this simple approach worked nicely for me, and I hope it does likewise for you:\n",
    "\n",
    "- Open a terminal and run the \"NVIDIA System Management Interface\" command `nvidia-smi`.\n",
    "- Note your CUDA version number which should appear in the upper right corner of the `nvidia-smi` output.\n",
    "- Install `cupy` by running the appropriate terminal command for your CUDA version. If you are running CUDA 10.2, the installation command is `pip install cupy-cuda102`.\n",
    "- Run one of the sample snippets from the `cupy` web page to make sure that things have installed properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1b)__ Modify the `fft_demo.py` code (shown below) so that it runs in parallel on the GPU using by replacing the calls to functions from `numpy.fft` with calls to the corresponding functions from `cupy.fft`.\n",
    "\n",
    "Note that `numpy` functions operate on `numpy` arrays and `cupy` functions operate on `cupy` arrays, so you will need to be able to get data across the \"digital divide\". For that purpose, check out the documentation for `cupy.asarray()` (to get `numpy` data into `cupy`) and `cupy.asnumpy()` (to get `cupy` data back to `numpy`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fft_demo.py\n",
    "# Sample code illustrating use of numpy.fft for filtering and differentiating\n",
    "\n",
    "from  numba import cuda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft, fftfreq, ifft\n",
    "\n",
    "pts = 1000\n",
    "L = 100\n",
    "w0 = 2.0 * np.pi/L\n",
    "n1, n2, n3 = 10.0, 20.0, 30.0\n",
    "a1, a2, a3 = 1., 2., 3.\n",
    "\n",
    "#create signal data with 3 frequency components\n",
    "x = np.linspace(0,L,pts)\n",
    "y1 = a1*np.cos(n1*w0*x)\n",
    "y2 = a2*np.sin(n2*w0*x)\n",
    "y3 = a3*np.sin(n3*w0*x)\n",
    "y = y1 + y2 + y3\n",
    "\n",
    "#create signal including only 2 components\n",
    "y12 = y1 + y2\n",
    "\n",
    "#analytic derivative of signal\n",
    "dy = w0*(-n1*a1*np.sin(n1*w0*x)\n",
    "        +n2*a2*np.cos(n2*w0*x)\n",
    "        +n3*a3*np.cos(n3*w0*x) )\n",
    "\n",
    "#use fft.fftfreq to get frequency array corresponding to number of sample points\n",
    "freqs = fftfreq(pts)\n",
    "#compute number of cycles and radians in sample window for each frequency\n",
    "nwaves = freqs*pts\n",
    "nwaves_2pi = w0*nwaves\n",
    "\n",
    "# compute the fft of the full signal\n",
    "fft_vals = fft(y)\n",
    "\n",
    "#mask the negative frequencies\n",
    "mask = freqs>0\n",
    "#double count at positive frequencies\n",
    "fft_theo = 2.0 * np.abs(fft_vals/pts)\n",
    "#plot fft of signal\n",
    "plt.xlim((0,50))\n",
    "plt.xlabel('cycles in window')\n",
    "plt.ylabel('original amplitude')\n",
    "plt.plot(nwaves[mask], fft_theo[mask])\n",
    "plt.show()\n",
    "\n",
    "#create a copy of the original fft to be used for filtering\n",
    "fft_new = np.copy(fft_vals)\n",
    "#filter out y3 by setting corr. frequency component(s) to zero\n",
    "fft_new[np.abs(nwaves)==n3] = 0.\n",
    "#plot fft of filtered signal\n",
    "plt.xlim((0,50))\n",
    "plt.xlabel('cycles in window')\n",
    "plt.ylabel('filtered amplitude')\n",
    "plt.plot(nwaves[mask], 2.0*np.abs(fft_new[mask]/pts))\n",
    "plt.show()\n",
    "\n",
    "#invert the filtered fft with numpy.fft.ifft\n",
    "filt_data = np.real(ifft(fft_new))\n",
    "#plot filtered data and compare with y12\n",
    "plt.plot(x,y12, label='original signal')\n",
    "plt.plot(x,filt_data, label='filtered signal')\n",
    "plt.xlim((0,50))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#multiply fft by 2*pi*sqrt(-1)*frequency to get fft of derivative\n",
    "dy_fft = 1.0j*nwaves_2pi*fft_vals\n",
    "#invert to reconstruct sampled values of derivative\n",
    "dy_recon = np.real(ifft(dy_fft))\n",
    "#plot reconstructed derivative and compare with analuytical version\n",
    "plt.plot(x,dy,label='exact derivative')\n",
    "plt.plot(x,dy_recon, label='fft derivative')\n",
    "plt.xlim((0,50))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1c)__ Use `cupy` to do the following:\n",
    "\n",
    "- Create `noise` consisting of an array of `pts` random values chosen from a uniform distribution over the interval $[-3,3]$.\n",
    "- Create a noisy signal by adding noise to the original signal: `y_n = y + noise`\n",
    "- Compute and plot the frequency content of the noisy signal.\n",
    "- Create and apply an appropriate filter to suppress noise in the frequency domain.\n",
    "- Invert the filtered fft to obtain a \"denoised signal\".\n",
    "- Plot and compare the original, noisy, and denoised signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2)__ We looked at the Jacobi iteration method for solving systems derived from finite difference approximations. The \"big matrix\" version of the 1D Poisson equation involves an $n \\times n$ matrix $J(n)$ full of zeros except for the diagonals adjacent to the main diagonal where each of the entries is $1/2$. When we experimented with an iterative approach, we observed that the convergence was quite slow and that inspires a closer look at the eigenvalues and eigenvectors of the matrix $J(n)$.\n",
    "\n",
    "Use `cupy` and `cupyx.scipy.spare.diags()` to construct the matrix $J(n)$ and compute its leading eigenvalue (the one with the largest magnitude) and the associated eigenvector for $n = 50$ and $n = 500$.  \n",
    "\n",
    "Note that you may need to convert the sparse matrix to a dense array with `cupyx.scipy.sparse.dia_matrix.toarray()` before you can compute the eigenvalues/vectors.\n",
    "\n",
    "What is the value of the leading eigenvalue and how does it behave as $n$ becomes large?\n",
    "\n",
    "Provide a brief description of the corresponding eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ 3) __ Using `cupy`, explore the distribution of eigenvalues in random symmetric matrices. (Note that this concept has real applications in nuclear physics and quantum information theory. The seminal results are attributed to Eugene Wigner who won the Nobel Prize for Physics in 1963.)\n",
    "\n",
    "__3a)__ Write python code using `cupy` to implement a function `rand_mat_gauss(n)` that creates a real symmetric $n \\times n$ array of numbers selected from $N(0,1)$, the normal distribution with mean zero and standard deviation 1. Note that you can start by constructing a non-symmetric matrix $B$ and then construct the symmetric matrix $A = \\frac{1}{\\sqrt{2}}(B + B^T)$ whose entries should also belong to the distribution $N(0,1)$.\n",
    "\n",
    "__3b)__ Test your code by creating a \"small-ish\" (say $10 \\times 10$) array. Verify that the matrix is symmetric, and plot the histogram of the entries together with the normal distribution to verify that the distribution is plausible. For an example of how to do that with numpy, see\n",
    "https://www.tutorialspoint.com/python_data_science/python_normal_distribution.htm\n",
    "\n",
    "__3c)__ Create a matrix `m = rand_mat_gauss(n)` with $n = 1000$. Use `cupy` to compute the eigenvalues of the matrix, and plot the histrogram of the eigenvalues. (Recall that real symmetric matrices have real eigenvalues.) Describe the distribution of the eigenvalues.\n",
    "\n",
    "__3d)__ Repeat 3c with $n = 2000$ and $n = 4000$. Describe the distribution of the eigenvalues. What features are independent of $n$? Identify a feature $F$ that depends on $n$ and determine the relationship; i.e. find $F(n)$. (You may find it enlightening to scale your eigenvalues by a factor of $\\sqrt{n}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ PROBLEM 4 IS OPTIONAL.__ Here we explore how the results obtained in problem 3 depend on the distribution from which the random matrix entries are chosen.\n",
    "\n",
    "__4a)__ Repeat problem 3 but with matrix entries chosen uniformly from $\\{-1,1\\}$ instead of from a normal distribution. This time you will need to write a function `rand_mat_plusminus(n)` that produces an $n \\times n$ array that is symmetric and any individual element is equally likely to be $+1$ or $-1$.\n",
    "\n",
    "Again explore the distribution of the eigenvalues and the dependence on $n$. \n",
    "\n",
    "___For this problem, exclude the largest eigenvalue before computing the histogram.___\n",
    "\n",
    "\n",
    "When the distribution from which elements are chosen is changed, what is preserved and what changes?\n",
    "\n",
    "__4b)__ Repeat 4a but with matrix entries chosen randomly from a uniform distribution on the interval $[-1,1]$. This time you will need to write a function `rand_mat_uniform(n)` that produces an $n \\times n$ array that is symmetric and any individual element is chosen randomly from $[-1,1]$.\n",
    "\n",
    "Again explore the distribution of the eigenvalues and the dependence on $n$. When the distribution is changed this time, what is preserved and what changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
