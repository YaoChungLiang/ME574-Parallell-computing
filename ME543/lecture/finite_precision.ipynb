{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite Precision Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following discussion is based on:\n",
    "\n",
    "### Lessons in Scientific Computing: <br>Numerical Mathematics, Computer Technology, and Scientific Discovery\n",
    "##### ByNorbert Schorghofer\n",
    "\n",
    "\n",
    "Ch. 3 - Roundoff & Number Representation\n",
    "\n",
    "This book is available in electronic form from UW Libraries. Please get access to and read Ch. 3 (and whatever other sections you may find to be of interest).\n",
    "\n",
    "For more information on the details of IEEE754 Standard for Floating-Point Arithmetic, see the classic \"What Every Computer Scientist Should Know About Floating-Point Arithmetic,\" by David Goldberg, ACM Computing Surveys. A version of this paper is available in the readings folder of the class Canvas files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bit of context\n",
    "\n",
    "What is this class all about? \n",
    "<br>__Practical__ numerical methods for obtaining good approximate solutions to engineering problems (for which analytic solutions may not be readily available)\n",
    "\n",
    "What are __numerical methods__ about?\n",
    "<br>Using digital computers to obtain those good approximate solutions...\n",
    "\n",
    "Computers are now both:\n",
    "\n",
    "- Extremely fast/capable\n",
    "- Extremely dumb/literal\n",
    "\n",
    "The computer is not smarter than you, so you have to tell it __very explicitly__ what you want it to do. (_Exception?_)\n",
    "\n",
    "The specification of what to do is an __algorithm__:\n",
    "<br>Unambiguous finite rule that, after a finite number of steps provides a solution to a class of problems.\n",
    "\n",
    "(We will look at both algorithms and __their implementations as codes/programs__.)\n",
    "\n",
    "Algorithms have inputs (typically in $ℤ^n$ or $ℝ^n$) that are converted into outputs by a sequence of __elementary operations__ including `+,-,*,/`.\n",
    "\n",
    "__Well-conditioned problem__:\n",
    "<br>small change in input $\\iff$ small change in output\n",
    "\n",
    "__Numerically stable algorithm__:\n",
    "<br>actual computational error comparable to __unavoidable error__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why would there be unavoidable errors?\n",
    "- Exact representation of a real number can require infinitely many digits.\n",
    "- Infinite data storage requires infinite computing resources.\n",
    "- Memory chip prices have come down, but an infinite amount is neither physically nor economically possible.\n",
    "\n",
    "So we typically make a compromise and use finite precision numeric representations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.1 -  Number Representation\n",
    "\n",
    "What we think of as real numbers in an algorithm, we approximate for computing purposes as __floating-point__ numbers of the form:\n",
    "<br>$(-1)^s \\; (d_0.d_1 d_2 \\ldots d_{p-1}) \\; \\beta^e$\n",
    "<br>where $s\\in {0,1}$ indicates the sign\n",
    "<br>$p$ is the number of digits or __precision__\n",
    "<br>each digit $d_i \\in [0, 1, \\ldots, \\beta-1]$\n",
    "<br>$\\beta$ is the base and $e$ is the exponent.\n",
    "\n",
    "While we, as humans, tend toward base $\\beta = 10$, computers almost universally use a __binary representation with $\\beta = 2$__.\n",
    "\n",
    "The floating-point representation corresponds to a unique real number:\n",
    "$\\bar{x} = (-1)^s \\big( d_0 + \\frac{d_1} {\\beta} + \\frac{d_2}{\\beta^2} + \\ldots + \\frac{d_{p-1}}{\\beta^{p-1}} \\big) \\beta^e$\n",
    "\n",
    "Some real numbers have an exact (but not unique) floating-point representation; e.g. $x=0.5$ has the following representations:\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.0) \\; 2^{-1} = (-1)^0 \\; (1+\\frac{0}{2}) \\; 2^{-1} = \\frac{1}{2}$\n",
    "<br>and\n",
    "<br>$\\bar{x} = (-1)^0 \\; (0.1) \\; 2^0 = (-1)^0 \\; (0+\\frac{1}{2}) \\; 2^0 = \\frac{1}{2}$\n",
    "\n",
    "For uniqueness, choose the __normalized__ (first) version with $d_0 \\neq 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A floating point number system is defined by base $\\beta$, precision (number of digits) $p$, and range of exponents $[e_{min}, e_{max}]$.\n",
    "\n",
    "Let's take a look at an example: $\\beta=2, p=2, e \\in [-2,3]$.\n",
    "\n",
    "Positive normalized numbers:\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.0) \\; 2^{-2} = \\frac{1}{4}$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.1) \\; 2^{-2} = \\frac{3}{8}$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.0) \\; 2^{-1} = \\frac{1}{2}$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.1) \\; 2^{-1} = \\frac{3}{4}$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.0) \\; 2^0 = 1$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.1) \\; 2^0 = \\frac{3}{2}$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.0) \\; 2^1 = 2$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.1) \\; 2^1 = 3$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.0) \\; 2^2 = 4$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.1) \\; 2^2 = 6$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.0) \\; 2^3 = 8$\n",
    "<br>$\\bar{x} = (-1)^0 \\; (1.1) \\; 2^3 = 12$\n",
    "\n",
    "$\\bar{x} \\in {\\bf{X}} = ± \\{1/4, 3/8, 1/2, 3/4, 1, 3/2, 2, 3, 4, 6, 8, 12 \\}$\n",
    "\n",
    "- Not all reals can be represented\n",
    "\n",
    "- No representation for zero (although one can be designated)\n",
    "\n",
    "- Uneven spacing: larger gaps between larger numbers\n",
    "\n",
    "Typical usage: round real number $x$ to nearest element of $\\bf{X}$.\n",
    "<br>This incurs an __absolute error__: $\\lvert x-\\bar{x} \\rvert = E(x)$\n",
    "<br>Can also consider __relative error__: $$\\frac{E(x)}{\\lvert x \\rvert} = R(x)$$\n",
    "\n",
    "Generally, floating point systems aim to even out relative error - larger gaps occur between larger elements of $\\bf{X}$.\n",
    "\n",
    "Floating point systems have limitations in terms of arithmetic operations:\n",
    "\n",
    "$ 12 * 2 = 24 \\notin {\\bf X} \\implies$ overflow ($±$ `Inf`)\n",
    "<br>$\\frac{1}{4} / 2 = \\frac{1}{8} \\notin {\\bf X} \\implies$ underflow ( ±`0`, `NaN`)\n",
    "<br>IEEE754 __de-normalizes__ for gradual underflow: $(-1)^0 \\; (0.1) \\; 2^{-2} = \\frac{1}{8}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.2 - IEEE Standardization\n",
    "\n",
    "Most common floating point systems:\n",
    "\n",
    "- __Single precision__: 24 bits (biniary digits), 1 sign bit, 7 bits of exponent\n",
    "\n",
    "- __Double precision__: 52 bits (biniary digits), 1 sign bit, 11 bits of exponent\n",
    "\n",
    "Note that bit counts are multiples of 8 because hardware organizes the bits into __bytes__ (1 byte = 8 bits, single = 4 bytes, double = 8 bytes)\n",
    "\n",
    "__Single precision: 4 bytes, about 6-9 significant decimal digits\n",
    "<br>Double precision: 8 bytes, about 15-17 significant decimal digits__\n",
    "\n",
    "See Table 3.1 in \"Lessons in Scientific Computing\" for details of representation range.\n",
    "\n",
    "Consider details of rounding error for real number $x$ that rounds to $\\bar{x}$ so they agree to $p$ digits: \n",
    "\n",
    "<br>$\\bar{x} = x \\; (1 + \\epsilon)$\n",
    "\n",
    "$R(x) =  \\lvert \\epsilon \\rvert \\leq (1/2) \\beta^{1-p} = u$ __unit roundoff__ <br>($u$ is the upper bound on relative rounding error)\n",
    "\n",
    "Spacing between normalized floats is $2 u \\lvert x \\rvert$\n",
    "<br>For $x=1$, the gap is $2u$, so the next f.p. number available is $1 + 2u$.\n",
    "\n",
    "An alternative characterization of precision involves machine epsilon, $\\epsilon_{M}$, which is usually defined as the smallest number you can add to 1 without producing the result 1: $$\\overline{1+x} = 1 \\; \\forall x \\; s.t. \\; |x|<\\epsilon_M$$\n",
    "\n",
    "Either $u$ or $\\epsilon_M$ (which some authors define to differ by a factor of 2) provide a measure of the resolution of the number system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3.3 - Roundoff Sensitivity\n",
    "\n",
    "Consider how roundoff error in inputs propagates when performing floating point arithmetic operations.\n",
    "\n",
    "Let the real inputs be $x_1$ and $x_2$ with rounded versions $$\\bar{x}_1 = x_1 (1+\\epsilon_1)$$ $$\\bar{x}_2 = x_2 (1+\\epsilon_2)$$\n",
    "\n",
    "$\\epsilon$ indicates signed relative error bounded by $u < 10^{-6} <<1$ (for single and double precision)\n",
    "\n",
    "- Multiplication: \n",
    "$$\\bar{x}_1 * \\bar{x}_2 = x_1 (1+\\epsilon_1) * x_2 (1+\\epsilon_2)$$\n",
    "$$\\bar{x}_1 * \\bar{x}_2 = x_1 * x_2 \\; (1 + \\epsilon_1 +\\epsilon_2 + \\epsilon_1 * \\epsilon_2)$$\n",
    "\n",
    "Product of relative errors is VERY small, so ignore...\n",
    "$$\\bar{x}_1 * \\bar{x}_2 = x_1 * x_2 \\; (1 + \\epsilon_1 +\\epsilon_2 + \\ldots)$$\n",
    "<br> so __when multiplying, relative errors to add__.\n",
    "\n",
    "- Division: \n",
    "$$\\bar{x}_1 / \\bar{x}_2 = x_1 (1+\\epsilon_1) / (x_2 (1+\\epsilon_2))$$\n",
    "$$\\bar{x}_1 / \\bar{x}_2 = x_1 / x_2 (1 + \\epsilon_1) * \\frac{1}{1+\\epsilon_2}$$ \n",
    "$$\\approx x_1 / x_2 * (1 + \\epsilon_1) * (1 - \\epsilon_2 + \\epsilon^2 + \\ldots)$$\n",
    "$$\\approx x_1 / x_2 * (1 + \\epsilon_1 - \\epsilon_2 + \\ldots)$$\n",
    "\n",
    "Again ignore product of relative errors, so output error is bounded by sum of input relative errors.\n",
    "\n",
    "__Mutiply or divide: relative error bounded by sum of input relative errors.__\n",
    "\n",
    "- Addition: $$\\bar{x}_1 + \\bar{x}_2 = x_1 (1+\\epsilon_1) + x_2 (1+\\epsilon_2)$$\n",
    "$$= x_1 + x_2 + (x_1 * \\epsilon_1 + x_2 * \\epsilon_2) = (x_1 + x_2) * (1 + \\epsilon_+)$$\n",
    "$$\\implies \\lvert \\epsilon_+ \\rvert = \\frac{ \\lvert x_1 * \\epsilon_1 + x_2 * \\epsilon_2 \\rvert}{\\lvert x_1 + x_2 \\rvert} \\lessapprox u$$\n",
    "\n",
    "\n",
    "__Addition: Relative error near unit roundoff__\n",
    "<br>__if $x_1$ and $x_2$ have the same sign!__\n",
    "<br>__When $x_1 \\approx -x_2$ the denominator becomes arbitrarily small and the error is not well bounded.__\n",
    "\n",
    "__The main concern is Subtraction leading to__ ___Catastrophic cancellation___:<br>__Subtracting nearly equal numbers wipes out the significant digits and leaves noise...__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of how to deal with limitations of fixed precision arithmetic\n",
    "\n",
    "- Compute $x^2 - y^2$ in toy number system with $x=4$ and $y=2$\n",
    "<br>$\\bar{x} \\in {\\bf{X}} = ± \\{1/4, 3/8, 1/2, 3/4, 1, 2, 3, 4, 6, 8, 12 \\}$\n",
    "<br>Blindly computing $x*x = 4*4$ causes overflow\n",
    "<br>Instead, consider using your math skills:\n",
    "<br>Rewrite expression as $(x-y) * (x+y)$ so the computation becomes $(4-2) * (4+2) = 2*6 = 12$ which works!\n",
    "    <br>Note: No guarantee of exactness; e.g. $x=4$ and $y=3$\n",
    "$$(4-3) * (4+3) \\approx 1*8 = 8$$ (not exact, but better than overflow)\n",
    "    \n",
    "    More general approach to overflow: \n",
    "    <br>Normalize with units that make your numerical values close to 1\n",
    "    \n",
    "- Evaluate the roots of $a x^2 + b x + c = 0 = a(x-x_+)(x-x_-)$ using quadratic formula: \n",
    "<br>$$x_\\pm = \\frac{-b \\pm \\sqrt{b^2- 4 a c}}{2 a}$$\n",
    "What about this could be problematic?\n",
    "<br><br><br><br>\n",
    "<br>\n",
    "<br>\n",
    "When $4 a c \\ll b^2$ the square root is nearly equal to $b$, so if $b>0$ the root $x_+$ is subject to catastrophic cancellation. However the root $x_-$ should be OK and we know that $a* x_+ * x_- = c$.\n",
    "<br>$\\implies$ Effective plan for $b>0$ : \n",
    "\n",
    "    1) Compute $$q = b + \\sqrt{b^2 -4 a c}$$\n",
    "\n",
    "    2) Compute $$x_1 = -\\frac{q}{2a}$$ $$x_2 = \\frac{c}{a x_1} = -2 \\frac{c}{q}$$\n",
    "    \n",
    "    Shorghofer notes a couple possible improvements:\n",
    "\n",
    "    1) Compute $$q = (-1/2) (b + \\mathrm{sgn(b)} \\sqrt{b^2 -4 a c})$$ \n",
    "then roots are $$x_1 = \\frac{q}{a}$$ $$x_2 = \\frac{c}{a x_1} = \\frac{c}{q}$$\n",
    "\n",
    "    Note that basic python does not include a \"sign\" function. You can define your own or import one from python's symbolics package `sympy`.\n",
    "    \n",
    "- Sometimes you can rearrange to avoid cancellation.\n",
    "<br> Consider a sum where cancellation would be of concern:\n",
    "$$ S = 1 -\\frac{1}{2}+\\frac{1}{3}- \\frac{1}{4}+\\ldots$$\n",
    "<br>Each pair of terms can be collected over common denominator to give:\n",
    "$$ S = \\frac{1}{1 \\cdot 2}+\\frac{1}{3 \\cdot 4} +\\ldots$$\n",
    "<br>Subtraction is eliminated and cancellation trouble is avoided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASIDE: Interval arithmetic\n",
    "\n",
    "- An interesting alternative approach to dealing with roundoff errors\n",
    "\n",
    "- Instead of trying to represent a particular real number (which we cannot do with finite precision), keep track of the lower and upper bounds of an interval that is guaranteed to contain the exact number\n",
    "\n",
    "- Output of an operation needs to guarantee inclusion of the exact answer\n",
    "\n",
    "- Useful property for root-finding/isolation: finite convergence\n",
    "\n",
    "- An example due to Rump [E. Loh, G. W. Walster, “Rump’s example revisited”, Reliable Computing, vol. 8 (2002), n. 2, pp. 245–248.]\n",
    "\n",
    "$$f(x,y) = (\\frac{1335}{4} - x^2) y^6 +x^2 (11 x^2 y^2 - 121 y^4 -2) + \\frac{11}{2} y^8 + \\frac{x}{2 y}$$\n",
    "\n",
    "This is a function with rational coefficients, so with rational (or integer) arguments, it can be evaluated exactly (e.g. with Mathematica): \n",
    "$$f(77617, 33096) = -\\frac{54767}{66192} \\approx −0.827396\\ldots$$\n",
    "\n",
    "Now let's try floating point evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):\n",
    "    return ((333.75 - x**2)* y**6 + x**2 * (11* x**2 * y**2 - 121 * y**4 - 2) + 5.5 * y**8 + x/(2*y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1726039400531787"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " f(77617.0, 33096.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't even evaluate the function, so would there be any chance of locating its roots?\n",
    "\n",
    "The answer turns out to be YES (but we will stick to the simpler case with 1 variable)\n",
    "\n",
    "Basic plan: \n",
    "\n",
    "Define __interval extensions__ of arithmetic functions that reliably contain the correct result\n",
    "\n",
    "Evaluate the interval extension of the function over some input interval to obtain an output interval\n",
    "\n",
    "If the output interval includes 0, then the input interval can contain a root\n",
    "\n",
    "Subdivide and evaluate on subinterval until the output interval excludes 0 $\\implies$ NO ROOTS in the subinterval\n",
    "\n",
    "Eventually (in finite steps) obtain a set of narrow intervals that are candidate root locations\n",
    "\n",
    "For more details see the following paper available on the Canvas page.\n",
    "\n",
    "\"Interval Arithmetic: Python Implementation and Applications,\" Proceedings of the 7th Python in Science Conference (SciPy 2008)\n",
    "\n",
    "by Stefano Taschini, Altis Investment Management AG\n",
    "<br>(note the affiliation...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_interval(x0,x1):\n",
    "    x_min, x_max = min(x0,x1), max(x0,x1)\n",
    "    return np.array([x_min, x_max])\n",
    "\n",
    "def i_add(x,y):\n",
    "    \"\"\"\n",
    "    perform interval addition\n",
    "    \n",
    "    arguments:\n",
    "        x, y: intervals represented as numpy arrays of length 2\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.array([x[0] + y[0], x[1] + y[1]])\n",
    "\n",
    "def i_mult(x,y):\n",
    "    \"\"\"\n",
    "    perform interval multiplication\n",
    "    \n",
    "    arguments:\n",
    "        x, y: intervals represented as numpy arrays of length 2\n",
    "    \"\"\"\n",
    "    products = np.array([x[0]*y[0],x[0]*y[1],x[1]*y[0],x[1]*y[1]])\n",
    "    out_min = np.min(products)\n",
    "    out_max = np.max(products)\n",
    "    \n",
    "    return make_interval(out_min, out_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = make_interval(0,1)\n",
    "y = make_interval(2,3)\n",
    "z = make_interval(-2,1)\n",
    "i_add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6,  3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_mult(y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_f(x):\n",
    "    return i_mult(x, 1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12,   8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = make_interval(-3,2)\n",
    "i_f(x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can contain roots of $f$, so subdivide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def i_left(x):\n",
    "    mid = (x[0]+x[1])/2\n",
    "    return make_interval(x[0],mid)\n",
    "\n",
    "def i_right(x):\n",
    "    mid = (x[0]+x[1])/2\n",
    "    return make_interval(mid, x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-12.  ,  -0.75]), array([-2.,  3.]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x00 = i_left(x0)\n",
    "x01 = i_right(x0)\n",
    "i_f(x00), i_f(x01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the left interval contains only negative values, so no roots can exist there. <br>Continue sudividing right interval `x01`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.5 ,  0.75]),\n",
       " array([-0.75 ,  1.125]),\n",
       " array([0.75, 2.  ]),\n",
       " array([-2. ,  0.5]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x010 = i_left(x01)\n",
    "x011 = i_right(x01)\n",
    "x010, i_f(x010), x011, i_f(x011)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both intervals can have roots, but let's choose to focus on (and continue subdividing) the right interval `x011`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75 , 1.375]),\n",
       " array([-0.515625,  0.34375 ]),\n",
       " array([1.375, 2.   ]),\n",
       " array([-2.      , -0.515625]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0110 = i_left(x011)\n",
    "x0111 = i_right(x011)\n",
    "x0110, i_f(x0110), x0111, i_f(x0111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the right subinterval is entirely negative, so continue subdividing the left subinterval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75  , 1.0625]),\n",
       " array([-0.06640625,  0.265625  ]),\n",
       " array([1.0625, 1.375 ]),\n",
       " array([-0.515625  , -0.06640625]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x01100 = i_left(x0110)\n",
    "x01101 = i_right(x0110)\n",
    "x01100, i_f(x01100), x01101, i_f(x01101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the right subinterval is root-free, so continue subdiving left sub-interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75   , 0.90625]),\n",
       " array([0.0703125, 0.2265625]),\n",
       " array([0.90625, 1.0625 ]),\n",
       " array([-0.06640625,  0.09960938]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x011000 = i_left(x01100)\n",
    "x011001 = i_right(x01100)\n",
    "x011000, i_f(x011000), x011001, i_f(x011001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discard the left subinterval and continue on the right...\n",
    "\n",
    "But it is clear already that this is an example of why you need to have coding skills. Doing this by hand is going to produce mistakes that you want to avoid.\n",
    "\n",
    "When it is coded up and working reliably, what happens?\n",
    "\n",
    "It is guaranteed that in a finite number of steps the interval stabilizes; i.e. the output interval that can contain a root is the same as the input interval so you know you can stop. (Even though you do not really know a root exists unless you have other information...)\n",
    "\n",
    "Here is an example from the paper to illustrate finite interval convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](intervalRoots.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What have we neglected to make sure that our interval arighmetic is \"working reliably\"?\n",
    "<br><br><br><br><br><br><br><br>\n",
    "\n",
    "Need to control roundoff direction to sensure containment:\n",
    "<br>Round down for lower bound\n",
    "<br>Round up for upper bound"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
