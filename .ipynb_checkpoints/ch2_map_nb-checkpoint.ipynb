{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch. 2 - Function Evaluation and the Map Pattern\n",
    "\n",
    "For our first software application, or \"app\", we pick something that\n",
    "is straightforward in terms of both explanation and implementation.\n",
    "The basic task is to evaluate a function over an array of evenly spaced\n",
    "points. Performing a particular operation on every element of an array\n",
    "is a common computing task referred to as the \"map\" pattern. Given\n",
    "that we are working with a map pattern, we use \"map\" as the name\n",
    "for this first example app. To be concrete, we choose a simple trigonometric\n",
    "polynomial function\n",
    "\n",
    "$$f (x) = 1 - 2 sin(\\pi x)^2 $$ (2.1)\n",
    "\n",
    "and evaluate it at N points equally spaced on the interval $0 \\leq x \\leq 1$.\n",
    "\n",
    "## 2.1 - Serial Implementation: The Map App\n",
    "\n",
    "We start with a serial implementation using some Python essentials\n",
    "and, in the following section \"Parallelizing the Map App\", we show\n",
    "how to efficiently convert to a parallel implementation.\n",
    "\n",
    "To keep track of code for multiple, and often larger, projects we offer\n",
    "a few suggestions that should make it easier for you to keep track of\n",
    "your code and easier for us to refer to specific files and line numbers:\n",
    "\n",
    "- We find it convenient to create a directory where Python projects\n",
    "can be stored in sub-directories. We refer to this directory by the\n",
    "name _apps_ although the full address on your system will be longer\n",
    "than that.\n",
    "\n",
    "- For each app, we create a sub-directory with the name of the app.\n",
    "We refer to the map app as _map_, so we refer to the directory\n",
    "where the code files are stored as _apps/map/_.\n",
    "\n",
    "- Within the sub-directory for each app, we create a _main.py_ file. The\n",
    "particular version for the map app can be referred to uniquely as\n",
    "_apps/map/main.py_.\n",
    "\n",
    "- Each app typically includes other files besides _main.py_. In this case,\n",
    "we create a _serial.py_ file to hold definitions of the functions called within `main()` in this serial implementation of the app. That file\n",
    "can be uniquely referred to as _apps/map/serial.py_.\n",
    "\n",
    "Below is the listing of the file  _apps/map/serial.py_.\n",
    "\n",
    "```\n",
    "File: serial.py\n",
    "01: import math\n",
    "02: import numpy as np\n",
    "03: \n",
    "04: PI = np.pi\n",
    "05: \n",
    "06: def s(x0):\n",
    "07: \treturn (1.-2*math.sin(PI*x0)**2)\n",
    "08: \n",
    "09: def sArray(x):\n",
    "10: \tn = x.shape[0]\n",
    "11: \tf = np.zeros(n)\n",
    "12: \tfor i in range(n):\n",
    "13: \t\tf[i] = s(x[i])\n",
    "14: \treturn f\n",
    "```\n",
    "\n",
    "$$ \\text{Listing 2.1: }  apps/map/serial.py $$\n",
    "\n",
    "\n",
    "The first step in the serial implementation involves creating a Python\n",
    "function equivalent to Equation  2.1, which we call `s()`. As we\n",
    "head toward parallelism, we have a particular interest in operating\n",
    "on arrays of data, so our second function, `sArray()` , takes in the N\n",
    "points on the interval $0 \\leq x \\leq 1$ and passes each of them to `s()`\n",
    "to generate the corresponding array of function values. The complete\n",
    "code for both these functions can be seen in Listing 2.1.\n",
    "\n",
    "The function `s()` is shown on on Lines 4-5. `s()` takes in a single value and operates on it according to the given function, for\n",
    "our purposes Equation 2.1. Lines 7-14 contain the function `sArray()`, which is meant to take in a numpy array cotaining the N interval\n",
    "points and output an array containing N computed function values.\n",
    "On Line 8 we start by determining the size of the input array by using\n",
    "the size or shape attribute of the numpy array. (See the numpy documentation for more details about array attributes and methods.). The input array size determines both the range of indices to loop over and how large the output array\n",
    "needs to be. On Line 9 an empty output array is created. Lines\n",
    "11-12 contain the for loop, which executes over the index values\n",
    "$[0, 1, 2, . . . , N-1]$. (If range is only given an end value the default starting value is 0.) On each loop `s()` is called with the $i^{th}$ input value and the function value is stored as the $i^{th}$ element in the  output array `f[i]`. Finally, Line 14 returns the `f` array containing the evaluated function values.\n",
    "\n",
    "To complete the `map` app, we need to create _apps/map/main.py_ which contains the definition of a `main()` function that controls execution.\n",
    "An implementation of _apps/map/main.py_ is shown in Listing\n",
    "2.2. \n",
    "\n",
    "```\n",
    "File: main.py\n",
    "01: import math\n",
    "02: import numpy as np\n",
    "03: import matplotlib.pyplot as plt\n",
    "04: \n",
    "05: N = 64\n",
    "06: \n",
    "07: def main():\n",
    "08: \tx = np.linspace(0, 1, N, dtype=np.float32)\n",
    "09: \t\n",
    "10: \tfrom serial import sArray\n",
    "11: \tf = sArray(x)\n",
    "12: \tplt.plot(x, f, 'o', label='1-2*Sin(2*PI*x))**2')\n",
    "13: \tplt.legend()\n",
    "14: \tplt.show()\n",
    "15: \n",
    "16: if __name__ == '__main__':\n",
    "17: \tmain()\n",
    "\n",
    "```\n",
    "$$ \\text{Listing 2.2: }  apps/map/main.py $$\n",
    "\n",
    "Lines 1-3 import the necessary libraries (`numpy` is imported for array functionality,\n",
    "`matplotlib.pyplot` is\n",
    "imported for plotting, and `seaborn` is\n",
    "an optional library that aims to improve the aesthetics of the plots.) and Line 5 assigns a value of N to be used when defining the array size. Lines 7-14 define the `main()` function that controls execution. To create an array\n",
    "of N input values, on Line 8, we use numpy’s `linspace()` function to produce a list of N values uniformly distributed on $[0,1]$. Line 10\n",
    "imports our definition of `sArray()` from _apps/map/serial.py_, and\n",
    "Line 11 calls `sArray()` with the array `x` and stores the results in `f`.\n",
    "Lines 13-14 plot and display `f`, the evaluated function array, and\n",
    "Lines 16-17 call for execution of `main()`. From `main()` we can call\n",
    "`sArray()` to execute `s()` on the desired array of values. After\n",
    "execution, the script should produce a pop-up plot of the computed\n",
    "values of `s()`.\n",
    "\n",
    "> `__name__` is referred to as a __dunder__.\n",
    "Whenever you run a Python\n",
    "script, it is assigned a name associated with \n",
    "the `__name__` variable. Whichever\n",
    "file is being explicitly executed by\n",
    "the interpreter is given the name\n",
    "`__main__`. The conditional `if __name__ == '__main__ ':` prevents\n",
    "`main()` from running if the file\n",
    "where to be imported by a different\n",
    "module. This is not required, but it\n",
    "is a good habit to always include it.\n",
    "\n",
    "## 2.2 Parallelizing the Map App\n",
    "\n",
    "The basic plan for parallelization is to make minimal changes to _apps/map/main.py_, and focus on an alternative CUDA-powered, parallel implementation\n",
    "of the `sArray()` function in _apps/map/parallel.py_.\n",
    "\n",
    "Listing 2.3 shows the code for the parallelized version _apps/map/parallel.py_, and Listing 2.4 shows a side-by-side comparison with _apps/map/parallel.py_ on the left and _apps/map/serial.py_ on the right. From this side-by-side comparison it is apparent that not too many changes are needed to convert the serial implementation to the parallel implementation.\n",
    "Let’s walk through the changes line by line to see what is needed to take advantage of GPU-based parallelism.\n",
    "\n",
    "> At this point, it might be helpful to open an extra copy of the notebook to keep Listing 2.4 visible for reference while reading through the line-by-line description of the code.\n",
    "\n",
    "```\n",
    "File: parallel.py\n",
    "01: import math\n",
    "02: import numpy as np\n",
    "03: from numba import jit, cuda, float32\n",
    "04: \n",
    "05: PI = np.pi\n",
    "06: TPB = 32\n",
    "07: \n",
    "08: @cuda.jit(device = True)\n",
    "09: def s(x0):\n",
    "10: \treturn (1.-2.*math.sin(PI*x0)**2)\n",
    "11: \n",
    "12: @cuda.jit #Lazy compilation\n",
    "13: #@cuda.jit('void(float32[:], float32[:])') #Eager compilation\n",
    "14: def sKernel(d_f, d_x):\n",
    "15: \ti = cuda.grid(1)\n",
    "16: \tn = d_x.shape[0]\t\n",
    "17: \tif i < n:\n",
    "18: \t\td_f[i] = s(d_x[i])\n",
    "19: \n",
    "20: def sArray(x):\n",
    "21: \tn = x.shape[0]\n",
    "22: \td_x = cuda.to_device(x)\n",
    "23: \td_f = cuda.device_array(n, dtype = np.float32) #need dtype spec for eager compilation\n",
    "24: \tblockdims = TPB\n",
    "25: \tgridDims = (n+TPB-1)//TPB\n",
    "26: \tsKernel[gridDims, blockDims](d_f, d_x)\n",
    "27:\n",
    "28: \treturn d_f.copy_to_host()\n",
    "```\n",
    "$$ \\text{Listing 2.3: }  apps/map/parallel.py $$\n",
    "\n",
    "\n",
    "```\n",
    "File: parallel.py\t\t\t\t\t\t\t\t\tFile: serial.py\n",
    "01: import math\t\t\t\t\t\t\t\t\t\timport math\n",
    "02: import numpy as np\t\t\t\t\t\t\t\timport numpy as np\n",
    "03: from numba import jit, cuda, float32\n",
    "04: \n",
    "05: PI = np.pi\t\t\t\t\t\t\t\t\t\tPI = np.pi\n",
    "06: TPB = 32\n",
    "07: \n",
    "08: @cuda.jit(device = True)\n",
    "09: def s(x0):\t\t\t\t\t\t\t\t\t\tdef s(x0):\n",
    "10: \treturn (1.-2.*math.sin(PI*x0)**2)\t\t\t\treturn (1.-2.*math.sin(PI*x0)**2)\n",
    "11: \n",
    "12: @cuda.jit #Lazy compilation\n",
    "13: #@cuda.jit('void(float32[:], float32[:])') \n",
    "14: def sKernel(d_f, d_x):\n",
    "15: \ti = cuda.grid(1)\n",
    "16: \tn = d_x.shape[0]\t\n",
    "17: \tif i < n:\n",
    "18: \t\td_f[i] = s(d_x[i])\n",
    "19: \n",
    "20: def sArray(x):\t\t\t\t\t\t\t\t\tdef sArray(x):\n",
    "21: \tn = x.shape[0]\t\t\t\t\t\t\t\t\tn = x.shape[0]\n",
    "22: \td_x = cuda.to_device(x)\t\t\t\t\t\t\n",
    "23: \td_f = cuda.device_array(n,dtype=np.float32) \tf = np.zeros(n)\n",
    "24: \tblockdims = TPB\n",
    "25: \tgridDims = (n+TPB-1)//TPB\n",
    "26: \tsKernel[gridDims, blockDims](d_f, d_x)\t\t\tfor i in range(n):\n",
    "27:\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tf[i] = s(x[i])\n",
    "28: \treturn d_f.copy_to_host()\t\t\t\t\t\treturn f\n",
    "\n",
    "```\n",
    "\n",
    "$$ \\text{Listing 2.4: Side by side comparison of } \\\\\n",
    "apps/map/parallel.py \\text{ and }\n",
    "apps/map/serial.py $$\n",
    "\n",
    "\n",
    "In Listing 2.3, Line 3 contains the first change between the serial and parallel versions. An additional import statement is added where the\n",
    "cuda module is imported from the numba library. This provides the essential support for parallelization.\n",
    "Line 5 defines `TPB`, a global variable that will be used when the kernel is launched to specify the number of threads in each block.\n",
    "\n",
    "> `TPB` stands for __Threads Per Block__.\n",
    "The value of `TPB` can have an effect\n",
    "on performance, but choosing an\n",
    "optimal value is hardware dependent.\n",
    "A reliable rule of thumb is to make `TPB`\n",
    "a multiple of 32, which corresponds\n",
    "to the size of a warp. While we are\n",
    "working with small arrays, we choose\n",
    "`TPB = 32`. This variable will be used in the parallel implementaton of `sArray()`. \n",
    "\n",
    "The most significant changes made in the conversion from serial\n",
    "to parallel involve the introduction of the `sKernel()` function and the modification of `sArray()`. While the serial implementation of `sArray()` consists of a loop that iterates over the entries in the array `x`, calling\n",
    "`s()` for each element, the parallel version replaces the serial loop structure with a new version that we implement in two parts:\n",
    "\n",
    "- A __kernel__ function, or global function, that executes the code inside\n",
    "the loop in parallel on the GPU. Here the kernel function is called `sKernel()` and is defined on Lines 12-18. Kernel functions are called from the host (CPU) and execute on the device (GPU). In CUDA terminology, such a function (which is neither exclusively a host function nor a device function) is classified as global.\n",
    "- A __wrapper__, or launcher function, that does a bit of necessary bookkeeping and calls for execution of the kernel. Here the wrapper function is the new version of `sArray()` which is defined on Lines 20-28.\n",
    "\n",
    "Let’s start by looking at the details of the wrapper function. The function arguments of `sArray()` remain unchanged: both the serial and parallel versions take in an array of values. The parallel version of `sArray()` is derived from the serial version by replacing the loop with some array definitions and a kernel call.\n",
    "\n",
    "On Line 21, we use the `shape` attribute of the numpy array `x` to obtain the number of entries in the input array. The value `n = x.shape[0]` will be used to both determine the size of the output array and to calculate the value of `BPG` (short for __Blocks Per Grid__), the number of blocks required to cover the array of data. \n",
    "\n",
    "Since a kernel function cannot directly access the input from or write the output directly to a host array (on the CPU side of the PCIe bus), we create \"mirror\" arrays on the device, called __device arrays__. On Lines 22-23 the device arrays `d_x` and `d_f` are created. \n",
    "\n",
    "> We employ a common notation and\n",
    "use the prefix `d_` to distinguish\n",
    "between a host array and a device array\n",
    "\n",
    "On Line 22 we copy the `x` array, created on the host side, to `d_x` the device side using `d_x = cuda.to_device(x)`. Line 23 creates an empty device array `d_f` that can store `n` 32-bit floating point entries, using the built-in numba function `cuda.device_array()` .\n",
    "\n",
    "> `d_f` can also be created by calling\n",
    "`cuda.to_device()` on an empty or\n",
    "initialized array created on the host side\n",
    "but this requires more steps and is\n",
    "slower. Directly creating a device array of zeros is not yet supported in numba, so to be really sure that your device array does not include any random bits, it may be worthwhile to create a device array by copying an initialized host array.\n",
    "\n",
    "The final step before launching the kernel is to establish the kernel’s __execution configuration parameters__ to specify the number of threads and blocks in the computational grid. We take a typical approach by directly specifying the number of threads in each block (by assigning a constant value to `TPB`) and then determining the number of blocks necessary to cover every array element. A common trick to make sure that the grid is fully covered involves computing `(n + TPB - 1)//TPB` which ensures that the integer division always rounds up. \n",
    "\n",
    "> `//` forces integer division in\n",
    "Python 3.\n",
    "\n",
    "On lines 24-25, the variables `gridDims` and `blockDims`, which will appear in thekernel call, are assigned the desired execution parameter values `BPG` and `TPB`. \n",
    "\n",
    "> This is an optional notational convenience to give kernel calls have a more uniform appearance. It is perfectly acceptable for `TPB` and `BPG` to appear directly in the execution parameters of your kernel calls.\n",
    "\n",
    "Line 26 calls for execution of the kernel which introduces a bit of new syntax. As with all function calls, it starts with the function name and ends with parentheses containing a comma-separated list of arguments.\n",
    "The new element is in the middle: square brackets containing two arguments separated by commas:\n",
    "\n",
    "```\n",
    "kernel[gridDim, blockDim](args)\n",
    "```\n",
    "\n",
    "> The values of `gridDim` and\n",
    "`blockDim` will be tuples if the kernel\n",
    "is initialized with more than one\n",
    "grid dimension. There can also be optional\n",
    "third and fourth parameters to\n",
    "specify a computational stream and an\n",
    "allocation of dynamic shared memory. More on that later as needed...\n",
    "\n",
    "\n",
    "The entries in the square brackets specify the execution configuration as follows:\n",
    "\n",
    "- The first entry specifies the number of blocks in the computational\n",
    "grid.\n",
    "\n",
    "- The second entry specifies the number of threads in each block.\n",
    "\n",
    "After the kernel has computed the output, the data needs to be copied back to host memory. This the `return` statement on line 28 calls `copy_to_host()` so that the computed values stored in the device array `d_f` get copied back to the host side for further use (e.g. plotting).\n",
    "\n",
    "Let’s now look at the details of `sKernel()`, which specfies the computation to be carried out by a single thread. The code for a kernel function looks much like the code for any function in that it has a definition line followed by an indented code block, but with a few\n",
    "notable changes. On Line 12 `sKernel()` is preceded by a decorator, signified by the `@` symbol. This decorator `@cuda.jit()` indicates that the function `sKernel()` is a global function or kernel. An alternative version of the decorator with an optional argument specifying a __signature__ is included as a comment on line 13.\n",
    "\n",
    "The simpler version (just `@cuda.jit()`) without the optional signature specification leads to __lazy or just-in-time (JIT) compilation__. Since the compiler does not know the data types _a priori_, it waits until the kernel is actually called, infers the data types, and compiles \"just in time\" to execute. When the decorator includes the signature specifying the input and output data types, then __eager or ahead-of-time (AOT) compilation__ occurs, and the kernel code is compiled when the app is started rather than waiting for a kernel call to occur.\n",
    "\n",
    "> __Timing note:__ The first execution of code with lazy compilation will typically have a much longer execution time because it includes the kernel compilation time, so be sure to run lazy compilation code multiple times to get timings that reflect actual execution time.\n",
    "\n",
    "In this case, the signature  `void(float32[:], float32[:])` specifies that there are two arguments, each a 1-dimensional numpy array of 32-bit floats, and the return type is `void`. Note that all kernels have return type `void` because kernel functions, while launched from the host, run on the device (GPU) and cannot return a value directly to the host. The input list needs to include an argument so the results can be stored and then copied back to the host as needed. Note that the __wrapper__ function `sArray()` creates device arrays to store the input and output values that appear as arguments on line 26 where the kernel is called for execution.\n",
    "\n",
    "> Reminder: ___Kernel functions cannot return values, so provide an argument for storing results.___\n",
    "\n",
    "With the loop replaced by the kernel call, we still need some sort of index to uniquely identify each iteration. As seen on Line 16, CUDA provides built-in index and dimension variables which can be\n",
    "accessed within a global function which replace the traditional loop index. Each index value is associated with a computational block and\n",
    "thread within the computational grid:\n",
    "\n",
    "- `blockDim` gives the number of threads in a block.\n",
    "\n",
    "- `blockIdx` gives the index of a block in the grid.\n",
    "\n",
    "- `threadIdx` gives the index of a thread in the block.\n",
    "\n",
    "> CUDA supports grids up to dimension 3, so the built-in index variables are equivalent to python tuples with 3 entries designated by appending `.x`, `.y`, and `.z`. Here our arrays are 1D, we launch a 1D grid, and we are concerned solely with the `.x` components. By default, numba treats a numerical value as a 3-tuple with `.y` and `.z` components equal to zero, so integers suffice to specify execution parameters for 1D grids. \n",
    "\n",
    "The index for a thread is given by the sum of the number of blocks with smaller values of `blockIdx.x` multiplied by the size of a block,\n",
    "`blockDim.x`, plus the index of the thread in its block, `threadIdx.x`.\n",
    "This leads to the canonical formula for computing the index for a given\n",
    "thread within a one-dimensional computational grid:\n",
    "\n",
    "```\n",
    "i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "```\n",
    "\n",
    "This expression occurs so routinely that Numba offers a convenient\n",
    "shorthand:\n",
    "\n",
    "```\n",
    "i = cuda.grid(1)\n",
    "```\n",
    "\n",
    "> The argument of `grid()` indicates the dimension of the computational\n",
    "grid. We have a one-dimensional\n",
    "grid so the argument is 1.\n",
    "\n",
    "The index `i`, computed from the formula or from using `cuda.grid(1)`, acts as the replacement for the index provided by the `for` loop in the serial version of this code.\n",
    "\n",
    "Line 17 performs an essential bounds check to ensure that no thread tries to access memory that is \"out of bounds\"; i.e. with index beyond the dimensions of the array. If the data array size is not an integer multiple of `TPB` the \"last\" block (with largest `blockIdx.x` value) will include thread values beyond the bounds of the array indices. The conditional `if i < n:` ensures that only threads with index values corresponding to input and output array elements proceed to access an array element. \n",
    "\n",
    "The heart of each thread’s computing task appears on Line 18 with the call to `s()`. This function\n",
    "call is exactly the same as the function call within the loop of the serial `sArray()` function, but with the index `i` (which previousy arose as the iterator in the `for` loop) determined by the built-in index variables by<br>`i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x`<br> abbreviated in numba as `cuda.grid(1)`.\n",
    "\n",
    "The final change occurs on Line 8, with the addition of a decorator above `s()`. The function definition itself is unchanged but the decorator, `@cuda.jit(device = True)`, identifies `s()` as a device function so it gets compiled to run on the GPU. \n",
    "\n",
    "> The definition of any function, like `sArray()`, that is to be called from the device (i.e. by other functions executing on the GPU) must be preceeded by the decorator  `@cuda.jit(device=True)` that identifies __device functions__ for compilation to execute on the GPU. Device functions cannot be called from the CPU, but functions can be identified as \"device/host\" functions so that separate versions are compiled to run on CPU and GPU.\n",
    "\n",
    "You should have already executed the serial version of the the _map_ app, and\n",
    "you can now execute the parallel version by changing `serial` to `parallel` on line 10 of _apps/map/main.py_ (so the parallel version of `sArray()` is imported instead of the serial version imported previously).\n",
    "\n",
    "The parallel results should coincide with the serial results. You can check this visually by running both the serial and parallel code and\n",
    "looking at the plotted output. To validate further you can look to the suggested projects and create a comparison file to better analyze the differences, if any, between the two versions.\n",
    "\n",
    "> It is always good practice to verify\n",
    "that your parallel code produces the\n",
    "same result as the serial code it is\n",
    "meant to replace and \"accelerate\". In\n",
    "fact, it is good practice to perform such\n",
    "verification tests for various problem\n",
    "sizes and on the various types of\n",
    "hardware where your app is expected\n",
    "to run. ___Reducing the computation time but producing the wrong answer does not count as accelerating your app!___\n",
    "\n",
    "At this point you should have a working version of both serial and parallel versions of a Python _map_ app, and you are ready to move on to Homework 2 and future notebooks.\n",
    "\n",
    "## 2.3 Suggested projects\n",
    "\n",
    "1. Create a file _apps/map/compare.py_ that calls both the serial and parallel versions of `sArray()` and plots both\n",
    "results and the difference between them. Does the parallel implementation\n",
    "reproduce the the results of the serial implementation?\n",
    "\n",
    "2. Code up `cKernel()` and `cArray()`(analogous to `sKernel()` and\n",
    "`sArray()`) for the function $g(x) = cos(2 \\pi x)$. Evaluate your code\n",
    "and describe the relation between the values of $f(x)$ and $g(x)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
